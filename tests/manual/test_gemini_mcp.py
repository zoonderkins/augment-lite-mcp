#!/usr/bin/env python
"""
æ¸¬è©¦ Gemini local proxy èˆ‡ MCP augment-lite æ•´åˆ
"""
import os
import sys

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ° path (å¿…é ˆåœ¨ import ä¹‹å‰)
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# è¨­ç½®ç’°å¢ƒè®Šæ•¸ (å¿…é ˆåœ¨ import providers ä¹‹å‰)
# Port 8084 proxy ä½¿ç”¨ "dummy" å³å¯
os.environ['GEMINI_LOCAL_KEY'] = 'dummy'

print(f"âœ“ ç’°å¢ƒè®Šæ•¸è¨­ç½®: GEMINI_LOCAL_KEY={os.environ.get('GEMINI_LOCAL_KEY')}")

def test_gemini_basic():
    """æ¸¬è©¦ Gemini åŸºæœ¬èª¿ç”¨"""
    print("=" * 60)
    print("TEST 1: Gemini åŸºæœ¬èª¿ç”¨")
    print("=" * 60)

    from providers.registry import get_provider, openai_chat

    provider = get_provider('gemini-local')
    print(f"âœ“ Provider: {provider['model_id']}")
    print(f"âœ“ Base URL: {provider['base']}")

    response = openai_chat(
        provider,
        [{'role': 'user', 'content': 'ç”¨ä¸­æ–‡èªªä¸€å¥å•å€™èª'}],
        temperature=0.2,
        max_output_tokens=50
    )

    print(f"âœ“ Response: {response}")
    print(f"âœ“ Type: {type(response)}")
    assert response is not None, "Response should not be None"
    assert len(response) > 0, "Response should not be empty"
    print("âœ… TEST 1 PASSED\n")

def test_rag_search():
    """æ¸¬è©¦ RAG æœç´¢"""
    print("=" * 60)
    print("TEST 2: RAG æœç´¢ï¼ˆä¸ä½¿ç”¨ Subagentï¼‰")
    print("=" * 60)

    from retrieval.search import hybrid_search

    results = hybrid_search(
        query='Gemini configuration',
        k=3,
        project='auto'
    )

    print(f"âœ“ æ‰¾åˆ° {len(results)} å€‹çµæœ")
    for i, r in enumerate(results, 1):
        print(f"  {i}. {r['source'][:80]}... (score: {r.get('score', 0):.3f})")

    assert len(results) > 0, "Should find results"
    print("âœ… TEST 2 PASSED\n")

def test_subagent_filter():
    """æ¸¬è©¦ Subagent éæ¿¾"""
    print("=" * 60)
    print("TEST 3: Subagent éæ¿¾ï¼ˆä½¿ç”¨ Geminiï¼‰")
    print("=" * 60)

    from retrieval.subagent_filter import subagent_filter

    candidates = [
        {'text': 'System prompts é…ç½®æ”¯æ´å¤šæ¨¡å‹å®¢è£½åŒ–', 'source': 'config/system_prompts.yaml', 'score': 0.90},
        {'text': 'Gemini local proxy ä½¿ç”¨ Port 8084', 'source': 'docs/GEMINI_LOCAL_PROXY.md', 'score': 0.88},
        {'text': 'MCP å°ˆæ¡ˆç®¡ç†å·¥å…·', 'source': 'docs/MCP_PROJECT_MANAGEMENT.md', 'score': 0.75},
    ]

    print(f"âœ“ å€™é¸æ•¸: {len(candidates)}")

    filtered = subagent_filter(
        query='Gemini é…ç½®',
        candidates=candidates,
        max_results=2,
        model='gemini-local',
        use_llm=True
    )

    print(f"âœ“ éæ¿¾å¾Œ: {len(filtered)} å€‹çµæœ")
    for i, r in enumerate(filtered, 1):
        print(f"  {i}. {r['source']} (score: {r.get('score', 0):.3f})")

    assert len(filtered) > 0, "Should have filtered results"
    print("âœ… TEST 3 PASSED\n")

def test_answer_generation():
    """æ¸¬è©¦å®Œæ•´çš„ RAG + ç­”æ¡ˆç”Ÿæˆ"""
    print("=" * 60)
    print("TEST 4: å®Œæ•´ answer.generate æµç¨‹")
    print("=" * 60)

    from retrieval.search import hybrid_search
    from providers.registry import get_provider, openai_chat

    # Step 1: RAG æœç´¢
    query = 'What is Gemini local proxy'
    hits = hybrid_search(query, k=3, project='auto')

    print(f"âœ“ RAG æœç´¢: {len(hits)} å€‹çµæœ")

    # Step 2: æ§‹å»ºä¸Šä¸‹æ–‡
    context = '\n\n'.join([
        f"Source: {h['source']}\n{h['text'][:200]}..."
        for h in hits[:2]
    ])

    # Step 3: ä½¿ç”¨ Gemini ç”Ÿæˆå›ç­”
    provider = get_provider('gemini-local')

    messages = [
        {
            'role': 'user',
            'content': f"""Based on the following context, answer the question concisely.

Context:
{context}

Question: {query}

Answer in 2-3 sentences:"""
        }
    ]

    print("âœ“ èª¿ç”¨ Gemini...")
    response = openai_chat(
        provider,
        messages,
        temperature=0.2,
        max_output_tokens=200
    )

    print(f"âœ“ Gemini å›ç­”:\n{response}\n")

    assert response is not None, "Response should not be None"
    assert len(response) > 0, "Response should not be empty"
    print("âœ… TEST 4 PASSED\n")

def main():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("\nğŸš€ é–‹å§‹æ¸¬è©¦ Gemini + MCP augment-lite æ•´åˆ\n")

    try:
        test_gemini_basic()
        test_rag_search()
        test_subagent_filter()
        test_answer_generation()

        print("=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šé!")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
