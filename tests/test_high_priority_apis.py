#!/usr/bin/env python3
"""
é«˜å„ªå…ˆç´š MCP API æ¸¬è©¦
æ¸¬è©¦ answer.generate å’Œ index.rebuild
"""

import sys
import os
from pathlib import Path
import json
import subprocess

# Add project root to path
BASE = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(BASE))

def test_answer_generate():
    """æ¸¬è©¦ answer.generate - æ ¸å¿ƒåŠŸèƒ½"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 1: answer.generate")
    print("="*80)

    from retrieval.search import hybrid_search
    from providers.registry import get_provider, openai_chat
    from router import get_route_config
    from cache import make_key, get as cache_get, set as cache_set
    from guardrails.abstain import should_abstain, get_abstain_reason, suggest_query_improvements
    from tokenizer import estimate_tokens_from_messages
    from retrieval.subagent_filter import hybrid_search_with_subagent
    from retrieval.iterative_search import iterative_search, should_use_iterative_search
    from retrieval.search import evidence_fingerprints_for_hits

    try:
        # æ¸¬è©¦ 1.1: åŸºæœ¬æŸ¥è©¢
        print("\næ¸¬è©¦ 1.1: åŸºæœ¬æŸ¥è©¢")
        query = "å¦‚ä½•å»ºç«‹ç´¢å¼•"

        # åŸ·è¡Œæª¢ç´¢
        use_iterative = should_use_iterative_search(query, task_type="lookup")
        if use_iterative:
            hits = iterative_search(query, k_per_iteration=8, use_subagent=True, project="auto")[:5]
        else:
            hits = hybrid_search_with_subagent(query, k=8, use_subagent=True, project="auto")[:5]

        print(f"   æª¢ç´¢çµæœ: {len(hits)} å€‹çµæœ")

        if not hits:
            print("   âš ï¸  ç„¡æª¢ç´¢çµæœï¼Œè·³éå¾ŒçºŒæ¸¬è©¦")
            return True

        # æª¢æŸ¥ Guardrails
        if should_abstain(hits, min_diversity=2):
            reason = get_abstain_reason(hits, min_diversity=2)
            suggestions = suggest_query_improvements(query, hits)
            print(f"   âš ï¸  Guardrails æ‹’ç­”: {reason[:100]}...")
            print(f"   å»ºè­°: {suggestions[:100]}...")
            print("   âœ… Guardrails åŠŸèƒ½æ­£å¸¸")
        else:
            print("   âœ… è­‰æ“šå……è¶³ï¼Œå¯ä»¥ç”Ÿæˆå›ç­”")

        # æ§‹å»ºæ¶ˆæ¯
        system = ("ä½ åªèƒ½æ ¹æ“š Evidence å›ç­”ï¼›æ¯å€‹é—œéµçµè«–å¾Œé¢é™„ã€source:<file:line>|<url#heading>ã€‘ã€‚"
                  "è‹¥è­‰æ“šä¸è¶³è«‹æ˜ç¢ºèªªä¸çŸ¥é“ï¼Œä¸¦åˆ—å‡ºéœ€è¦çš„æª”æ¡ˆæˆ–é—œéµå­—ã€‚")
        evidence = "\n\n".join([f"[{h['source']}]\n{h['text']}" for h in hits])
        messages = [
            {"role": "system", "content": system},
            {"role": "user", "content": f"# Query\n{query}\n\n# Evidence\n{evidence}"},
        ]

        # ä¼°ç®— tokens
        total_tokens_est = estimate_tokens_from_messages(messages)
        print(f"   Token ä¼°ç®—: {total_tokens_est}")

        # ç²å–è·¯ç”±é…ç½®
        route_config = get_route_config("lookup", total_tokens_est, route_override="auto")
        model_alias = route_config["model"]
        max_output_tokens = route_config["max_output_tokens"]
        print(f"   è·¯ç”±: {model_alias}, max_output_tokens: {max_output_tokens}")

        # æ¸¬è©¦å¿«å– key ç”Ÿæˆ
        ev_fp = evidence_fingerprints_for_hits(hits)
        key = make_key(
            model=model_alias,
            messages=messages,
            extra={"temperature": 0.2, "task": "lookup", "route": "auto", "token_est": total_tokens_est},
            evidence_fingerprints=ev_fp,
            project="auto",
        )
        print(f"   å¿«å– key: {key[:50]}...")

        # æª¢æŸ¥å¿«å–
        cached = cache_get(key)
        if cached:
            print(f"   âœ… å¿«å–å‘½ä¸­")
            print(f"   å¿«å–ç­”æ¡ˆ: {cached.get('answer', '')[:100]}...")
        else:
            print(f"   âš ï¸  å¿«å–æœªå‘½ä¸­ï¼ˆé æœŸï¼Œé¦–æ¬¡æŸ¥è©¢ï¼‰")

        # æ¸¬è©¦ 1.2: ä¸åŒè·¯ç”±ç­–ç•¥
        print("\næ¸¬è©¦ 1.2: ä¸åŒè·¯ç”±ç­–ç•¥")
        routes = ["auto", "small-fast", "general"]
        for route in routes:
            try:
                route_config = get_route_config("lookup", total_tokens_est, route_override=route)
                print(f"   âœ… è·¯ç”± '{route}': {route_config['model']} (max_tokens: {route_config['max_output_tokens']})")
            except Exception as e:
                print(f"   âŒ è·¯ç”± '{route}' å¤±æ•—: {e}")

        # æ¸¬è©¦ 1.3: ä¸åŒä»»å‹™é¡å‹
        print("\næ¸¬è©¦ 1.3: ä¸åŒä»»å‹™é¡å‹")
        task_types = ["lookup", "refactor", "general"]
        for task_type in task_types:
            try:
                route_config = get_route_config(task_type, total_tokens_est, route_override="auto")
                print(f"   âœ… ä»»å‹™é¡å‹ '{task_type}': {route_config['model']}")
            except Exception as e:
                print(f"   âŒ ä»»å‹™é¡å‹ '{task_type}' å¤±æ•—: {e}")

        print("\nâœ… answer.generate æ‰€æœ‰æ¸¬è©¦é€šé")
        return True

    except Exception as e:
        print(f"\nâŒ answer.generate æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_index_rebuild():
    """æ¸¬è©¦ index.rebuild - ä¿®å¾©å¾Œçš„åŠŸèƒ½"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 2: index.rebuild (ä¿®å¾©å¾Œ)")
    print("="*80)

    from utils.project_utils import (
        get_project_status, auto_register_project, set_active_project,
        has_bm25_index, is_project_registered, get_active_project
    )

    test_project_name = "test-rebuild-project"
    test_project_root = str(BASE)

    try:
        # æ¸¬è©¦ 2.1: é©—è­‰ is_project_registered å‡½æ•¸å¯ç”¨
        print("\næ¸¬è©¦ 2.1: é©—è­‰ is_project_registered å‡½æ•¸")
        is_registered = is_project_registered(test_project_name)
        print(f"   âœ… is_project_registered('{test_project_name}'): {is_registered}")

        # æ¸¬è©¦ 2.2: è¨»å†Šæ¸¬è©¦å°ˆæ¡ˆï¼ˆå¦‚æœæœªè¨»å†Šï¼‰
        print("\næ¸¬è©¦ 2.2: è¨»å†Šæ¸¬è©¦å°ˆæ¡ˆ")
        if not is_registered:
            result = auto_register_project(test_project_name, test_project_root)
            if result:
                print(f"   âœ… å°ˆæ¡ˆå·²è¨»å†Š: {test_project_name}")
            else:
                print(f"   âŒ å°ˆæ¡ˆè¨»å†Šå¤±æ•—")
                return False
        else:
            print(f"   â„¹ï¸  å°ˆæ¡ˆå·²å­˜åœ¨: {test_project_name}")

        # æ¸¬è©¦ 2.3: æª¢æŸ¥å°ˆæ¡ˆç‹€æ…‹
        print("\næ¸¬è©¦ 2.3: æª¢æŸ¥å°ˆæ¡ˆç‹€æ…‹")
        status = get_project_status(test_project_name)
        print(f"   å°ˆæ¡ˆæ ¹ç›®éŒ„: {status.get('root', 'N/A')}")
        print(f"   BM25 ç´¢å¼•: {status.get('bm25_index', {})}")
        print(f"   å‘é‡ç´¢å¼•: {status.get('vector_index', {})}")

        # æ¸¬è©¦ 2.4: å»ºç«‹ BM25 ç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        print("\næ¸¬è©¦ 2.4: å»ºç«‹/é‡å»º BM25 ç´¢å¼•")
        has_index = has_bm25_index(test_project_name)
        print(f"   ç•¶å‰ BM25 ç´¢å¼•ç‹€æ…‹: {'å·²å­˜åœ¨' if has_index else 'ä¸å­˜åœ¨'}")

        build_script = BASE / "retrieval" / "build_index.py"
        cmd = [
            sys.executable,
            str(build_script),
            "--root", test_project_root,
            "--db", f"data/corpus_{test_project_name}.duckdb",
            "--chunks", f"data/chunks_{test_project_name}.jsonl",
        ]

        print(f"   åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")
        print(f"   âš ï¸  ç´¢å¼•å»ºç«‹å¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“ï¼ˆtimeout: 300sï¼‰...")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300, cwd=str(BASE))

        if result.returncode == 0:
            print("   âœ… BM25 ç´¢å¼•å»ºç«‹/é‡å»ºæˆåŠŸ")

            # æª¢æŸ¥æ–‡ä»¶
            chunks_file = BASE / "data" / f"chunks_{test_project_name}.jsonl"
            db_file = BASE / "data" / f"corpus_{test_project_name}.duckdb"

            if chunks_file.exists():
                size = chunks_file.stat().st_size / 1024 / 1024
                print(f"   chunks æ–‡ä»¶: {size:.2f} MB")
            if db_file.exists():
                size = db_file.stat().st_size / 1024 / 1024
                print(f"   æ•¸æ“šåº«æ–‡ä»¶: {size:.2f} MB")
        else:
            print(f"   âŒ BM25 ç´¢å¼•å»ºç«‹å¤±æ•—")
            print(f"   STDERR: {result.stderr[:500]}")
            return False

        # æ¸¬è©¦ 2.5: é‡å»ºå‘é‡ç´¢å¼•ï¼ˆå¦‚æœæœ‰ä¾è³´ï¼‰
        print("\næ¸¬è©¦ 2.5: é‡å»ºå‘é‡ç´¢å¼•")
        try:
            import torch
            import faiss
            import sentence_transformers

            build_vector_script = BASE / "retrieval" / "build_vector_index.py"
            cmd = [sys.executable, str(build_vector_script), "--project", test_project_name]

            print(f"   åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=180, cwd=str(BASE))

            if result.returncode == 0:
                print("   âœ… å‘é‡ç´¢å¼•é‡å»ºæˆåŠŸ")

                # æª¢æŸ¥æ–‡ä»¶
                vector_file = BASE / "data" / f"vector_index_{test_project_name}.faiss"
                if vector_file.exists():
                    size = vector_file.stat().st_size / 1024 / 1024
                    print(f"   å‘é‡ç´¢å¼•æ–‡ä»¶: {size:.2f} MB")
            else:
                print(f"   âš ï¸  å‘é‡ç´¢å¼•é‡å»ºå¤±æ•—ï¼ˆä¸å½±éŸ¿æ•´é«”æ¸¬è©¦ï¼‰")
                print(f"   STDERR: {result.stderr[:200]}")

        except ImportError as e:
            print(f"   âš ï¸  è·³éå‘é‡ç´¢å¼•æ¸¬è©¦ï¼ˆä¾è³´æœªå®‰è£ï¼‰")

        # æ¸¬è©¦ 2.6: é©—è­‰ç´¢å¼•å¯ç”¨
        print("\næ¸¬è©¦ 2.6: é©—è­‰ç´¢å¼•å¯ç”¨")
        from retrieval.search import hybrid_search

        set_active_project(test_project_name)
        results = hybrid_search("test query", k=3, project=test_project_name)

        if results:
            print(f"   âœ… ç´¢å¼•å¯ç”¨ï¼Œæª¢ç´¢åˆ° {len(results)} å€‹çµæœ")
        else:
            print(f"   âš ï¸  ç´¢å¼•å¯ç”¨ä½†ç„¡æª¢ç´¢çµæœï¼ˆå¯èƒ½æ˜¯æ­£å¸¸çš„ï¼‰")

        print("\nâœ… index.rebuild æ‰€æœ‰æ¸¬è©¦é€šé")
        return True

    except subprocess.TimeoutExpired:
        print("\nâŒ ç´¢å¼•å»ºç«‹è¶…æ™‚")
        return False
    except Exception as e:
        print(f"\nâŒ index.rebuild æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """åŸ·è¡Œæ‰€æœ‰é«˜å„ªå…ˆç´šæ¸¬è©¦"""
    print("\n" + "="*80)
    print("é«˜å„ªå…ˆç´š MCP API æ¸¬è©¦")
    print("="*80)
    print(f"å°ˆæ¡ˆæ ¹ç›®éŒ„: {BASE}")
    print(f"Python: {sys.version}")

    results = {}

    # æ¸¬è©¦ 1: answer.generate
    print("\n" + "="*80)
    print("é–‹å§‹æ¸¬è©¦ answer.generate")
    print("="*80)
    results["answer.generate"] = test_answer_generate()

    # æ¸¬è©¦ 2: index.rebuild
    print("\n" + "="*80)
    print("é–‹å§‹æ¸¬è©¦ index.rebuild")
    print("="*80)
    results["index.rebuild"] = test_index_rebuild()

    # æ‰“å°æ¸¬è©¦çµæœæ‘˜è¦
    print("\n" + "="*80)
    print("æ¸¬è©¦çµæœæ‘˜è¦")
    print("="*80)

    for test_name, result in results.items():
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{status}: {test_name}")

    # çµ±è¨ˆçµæœ
    passed = sum(1 for r in results.values() if r)
    total = len(results)
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰é«˜å„ªå…ˆç´šæ¸¬è©¦é€šéï¼")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} å€‹æ¸¬è©¦å¤±æ•—")
        return 1

if __name__ == "__main__":
    sys.exit(main())
