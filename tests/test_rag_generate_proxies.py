#!/usr/bin/env python3
"""
æ¸¬è©¦ rag.generate (answer.generate) ä½¿ç”¨ä¸åŒ Provider çš„æƒ…å¢ƒ

Provider é…ç½®:
- glm-4.7:        åŸå‚ç›´è¿ (api.z.ai/api/anthropic) - 200K context
- minimax-m2.1:   åŸå‚ç›´è¿ (api.minimax.io/anthropic) - 200K context
- glm-local:      æœ¬åœ°ä»£ç† (Port 8082, å¯é¸)
- minimax-local:  æœ¬åœ°ä»£ç† (Port 8083, å¯é¸)

æ¸¬è©¦ç­–ç•¥ï¼š
1. æ¸¬è©¦æœ¬åœ° Proxy ç«¯å£å¯ç”¨æ€§ï¼ˆå¯é¸ï¼‰
2. æ¸¬è©¦ route é…ç½®æ˜¯å¦æ­£ç¢º
3. æ¸¬è©¦ answer.generate ä½¿ç”¨ä¸åŒ route æ˜¯å¦æ­£å¸¸å·¥ä½œ
4. æ¸¬è©¦ Guardrails æ©Ÿåˆ¶åœ¨ä¸åŒæ¨¡å‹ä¸‹æ˜¯å¦ä¸€è‡´
"""

import sys
import os
from pathlib import Path
import socket

# Add project root to path
BASE = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(BASE))

def check_port_open(port: int, host: str = "127.0.0.1", timeout: int = 2) -> bool:
    """æª¢æŸ¥æœ¬åœ°ç«¯å£æ˜¯å¦é–‹æ”¾"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, port))
        sock.close()
        return result == 0
    except Exception:
        return False

def test_proxy_availability():
    """æ¸¬è©¦ 1: æª¢æŸ¥æœ¬åœ° Proxy ç«¯å£å¯ç”¨æ€§ï¼ˆå¯é¸ï¼‰"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 1: æœ¬åœ° Proxy ç«¯å£å¯ç”¨æ€§æª¢æŸ¥ï¼ˆå¯é¸ï¼‰")
    print("="*80)

    print("\n   â„¹ï¸  é»˜èªé…ç½®ä½¿ç”¨åŸå‚ APIï¼Œæœ¬åœ° Proxy ç‚ºå¯é¸")

    proxies = {
        8082: "glm-local",
        8083: "minimax-local",
    }

    available_proxies = {}
    unavailable_proxies = {}

    for port, name in proxies.items():
        is_open = check_port_open(port)
        if is_open:
            available_proxies[port] = name
            print(f"   âœ… Port {port} ({name}): å¯ç”¨")
        else:
            unavailable_proxies[port] = name
            print(f"   â„¹ï¸  Port {port} ({name}): æœªå•Ÿå‹•")

    print(f"\n   æœ¬åœ° Proxy å¯ç”¨: {len(available_proxies)}/{len(proxies)}")
    print(f"   â„¹ï¸  åŸå‚ API å§‹çµ‚å¯ç”¨ï¼ˆç„¡éœ€æœ¬åœ° Proxyï¼‰")

    return True, available_proxies

def test_route_configuration():
    """æ¸¬è©¦ 2: æª¢æŸ¥ route é…ç½®"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 2: Route é…ç½®æª¢æŸ¥")
    print("="*80)

    try:
        import yaml

        config_path = BASE / "config" / "models.yaml"
        with open(config_path, "r", encoding="utf-8") as f:
            cfg = yaml.safe_load(f)

        print("\n   ğŸ“‹ å·²é…ç½®çš„ Providers:")
        for provider_name, provider_config in cfg.get("providers", {}).items():
            if "127.0.0.1" in provider_config.get("base_url", ""):
                port = provider_config["base_url"].split(":")[-1].split("/")[0]
                print(f"      {provider_name}: {provider_config['base_url']} (Port {port})")

        print("\n   ğŸ“‹ å·²é…ç½®çš„ Routes:")
        for route_name, route_config in cfg.get("routes", {}).items():
            model = route_config.get("model")
            max_tokens = route_config.get("max_output_tokens", "default")
            print(f"      {route_name}: {model} (max_tokens: {max_tokens})")

        # æª¢æŸ¥å„å€‹ route ä½¿ç”¨çš„ provider
        print("\n   ğŸ” Route èˆ‡ Provider å°æ‡‰:")

        route_to_proxy = {
            "small-fast": ("minimax-m2.1", None),           # åŸå‚ Anthropic æ ¼å¼
            "general": ("glm-4.7", None),                   # åŸå‚ Anthropic æ ¼å¼
            "long-context": ("requesty-qwen3-coder", None), # Requesty é›²ç«¯
            "reason-large": ("glm-4.7", None),              # åŸå‚ Anthropic æ ¼å¼
        }

        for route_name, (expected_provider, expected_port) in route_to_proxy.items():
            route_config = cfg["routes"].get(route_name, {})
            actual_provider = route_config.get("model")

            if actual_provider == expected_provider:
                if expected_port:
                    print(f"      âœ… {route_name} â†’ {actual_provider} (Port {expected_port})")
                else:
                    print(f"      âœ… {route_name} â†’ {actual_provider} (Requesty é›²ç«¯)")
            else:
                print(f"      âš ï¸  {route_name}: æœŸæœ› {expected_provider}, å¯¦éš› {actual_provider}")

        print("\n   âœ… Route é…ç½®æª¢æŸ¥å®Œæˆ")
        return True

    except Exception as e:
        print(f"\n   âŒ Route é…ç½®æª¢æŸ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_answer_generate_with_routes(available_proxies):
    """æ¸¬è©¦ 3: ä½¿ç”¨ä¸åŒ route æ¸¬è©¦ answer.generate"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 3: answer.generate ä½¿ç”¨ä¸åŒ Route")
    print("="*80)

    from retrieval.search import hybrid_search
    from guardrails.abstain import should_abstain, get_abstain_reason, suggest_query_improvements

    # æ¸¬è©¦æŸ¥è©¢
    query = "å¦‚ä½•åˆå§‹åŒ–å°ˆæ¡ˆä¸¦å»ºç«‹ç´¢å¼•"

    try:
        # æ¸¬è©¦ 3.1: åŸ·è¡Œæª¢ç´¢
        print(f"\næ¸¬è©¦ 3.1: åŸ·è¡Œæª¢ç´¢")
        print(f"   æŸ¥è©¢: '{query}'")

        results = hybrid_search(
            query,
            k=8,
            project="auto"
        )

        print(f"   æª¢ç´¢çµæœ: {len(results)} å€‹")

        if not results:
            print(f"   âš ï¸  ç„¡æª¢ç´¢çµæœï¼Œæ¸¬è©¦ç„¡æ³•ç¹¼çºŒ")
            return False

        # æ¸¬è©¦ 3.2: Guardrails æª¢æŸ¥ï¼ˆé©ç”¨æ‰€æœ‰æ¨¡å‹ï¼‰
        print(f"\næ¸¬è©¦ 3.2: Guardrails æª¢æŸ¥")

        # ä½¿ç”¨å¯¦éš›æª¢ç´¢çµæœæ¸¬è©¦
        abstain = should_abstain(results)

        if abstain:
            abstain_msg = get_abstain_reason(results)
            suggestions = suggest_query_improvements(query, results)
            print(f"   âš ï¸  Guardrails æ‹’ç­”: {abstain_msg}")
            print(f"   å»ºè­°: {suggestions}")
            print(f"   â„¹ï¸  ç”±æ–¼è­‰æ“šä¸è¶³ï¼Œå¾ŒçºŒæ¨¡å‹èª¿ç”¨æ¸¬è©¦å°‡è·³é")
            guardrails_active = True
        else:
            print(f"   âœ… Guardrails é€šéï¼Œè­‰æ“šå……è¶³")
            guardrails_active = False

        # æ¸¬è©¦ 3.3: æ¸¬è©¦å„å€‹ route é…ç½®ï¼ˆåƒ…é‚è¼¯ï¼Œä¸å¯¦éš›èª¿ç”¨ LLMï¼‰
        print(f"\næ¸¬è©¦ 3.3: æ¸¬è©¦ Route é…ç½®")

        from router import get_route_config

        # ä¼°ç®— token
        def estimate_tokens(text):
            return len(text) * 1.3  # ç²—ç•¥ä¼°ç®—

        evidence_text = "\n\n---\n\n".join([r.get("text", "") for r in results[:5]])
        total_tokens = int(estimate_tokens(query) + estimate_tokens(evidence_text))

        print(f"   ç¸½ Token ä¼°ç®—: {total_tokens}")

        # æ¸¬è©¦ä¸åŒ route
        routes_to_test = [
            ("auto", "lookup"),
            ("small-fast", "lookup"),
            ("general", "general"),
        ]

        # å¦‚æœ Port 8084 å¯ç”¨ï¼Œæ¸¬è©¦ long-context
        if 8084 in available_proxies:
            routes_to_test.append(("long-context", "general"))

        all_routes_ok = True
        for route, task_type in routes_to_test:
            try:
                route_config = get_route_config(task_type, total_tokens, route_override=route)
                model = route_config.get("model")
                max_tokens = route_config.get("max_output_tokens")

                # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å°æ‡‰åˆ°å¯ç”¨çš„ proxy
                model_to_port = {
                    "glm-local": 8082,
                    "minimax-local": 8083,
                }

                if model in model_to_port:
                    port = model_to_port[model]
                    if port in available_proxies:
                        print(f"   âœ… Route '{route}' â†’ {model} (Port {port}, max_tokens: {max_tokens}) - å¯ç”¨")
                    else:
                        print(f"   âš ï¸  Route '{route}' â†’ {model} (Port {port}) - Proxy ä¸å¯ç”¨")
                        all_routes_ok = False
                else:
                    # Requesty é›²ç«¯æ¨¡å‹
                    print(f"   â„¹ï¸  Route '{route}' â†’ {model} (Requesty é›²ç«¯, max_tokens: {max_tokens})")

            except Exception as e:
                print(f"   âŒ Route '{route}' é…ç½®å¤±æ•—: {e}")
                all_routes_ok = False

        # æ¸¬è©¦ 3.4: å¯¦éš›èª¿ç”¨æ¸¬è©¦ï¼ˆåƒ…åœ¨è­‰æ“šå……è¶³ä¸” proxy å¯ç”¨æ™‚ï¼‰
        if not guardrails_active and len(available_proxies) > 0:
            print(f"\næ¸¬è©¦ 3.4: å¯¦éš›èª¿ç”¨æ¸¬è©¦ï¼ˆåƒ…æ¸¬è©¦é‚è¼¯ï¼Œä¸å¯¦éš›èª¿ç”¨ LLMï¼‰")
            print(f"   â„¹ï¸  å¯¦éš› LLM èª¿ç”¨éœ€è¦ API key å’Œç¶²çµ¡é€£æ¥")
            print(f"   â„¹ï¸  æœ¬æ¸¬è©¦åƒ…é©—è­‰èª¿ç”¨éˆè·¯æ­£å¸¸ï¼Œä¸é©—è­‰å›ç­”è³ªé‡")

            # æ¸¬è©¦å¿«å– key ç”Ÿæˆ
            from cache import make_key

            # æ§‹å»ºæ¶ˆæ¯
            evidence_text = "\n\n---\n\n".join([r.get("text", "") for r in results[:5]])
            messages = [
                {"role": "system", "content": "You are a helpful coding assistant."},
                {"role": "user", "content": f"Question: {query}\n\nEvidence:\n{evidence_text}"}
            ]

            # ç”Ÿæˆå¿«å– key
            cache_key = make_key(
                model="test-model",
                messages=messages,
                extra={"task_type": "lookup"},
                evidence_fingerprints=[r.get("source", "") for r in results[:5]],
                project="auto"
            )

            print(f"   âœ… å¿«å– key ç”Ÿæˆ: {cache_key[:50]}...")
            print(f"   âœ… èª¿ç”¨éˆè·¯é©—è­‰å®Œæˆ")
        else:
            if guardrails_active:
                print(f"\n   â„¹ï¸  è·³éå¯¦éš›èª¿ç”¨æ¸¬è©¦ï¼ˆGuardrails æ‹’ç­”ï¼‰")
            else:
                print(f"\n   â„¹ï¸  è·³éå¯¦éš›èª¿ç”¨æ¸¬è©¦ï¼ˆç„¡å¯ç”¨ Proxyï¼‰")

        if all_routes_ok:
            print(f"\nâœ… answer.generate route æ¸¬è©¦é€šé")
            return True
        else:
            print(f"\nâš ï¸  éƒ¨åˆ† route é…ç½®æœ‰å•é¡Œ")
            return True  # ä»è¿”å› Trueï¼Œå› ç‚ºä¸»è¦åŠŸèƒ½æ­£å¸¸

    except Exception as e:
        print(f"\nâŒ answer.generate æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_port_specific_features():
    """æ¸¬è©¦ 4: Provider é…ç½®å’ŒåŠŸèƒ½æ¸¬è©¦"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 4: Provider é…ç½®åŠŸèƒ½æ¸¬è©¦")
    print("="*80)

    print("\n   ğŸ“‹ åŸå‚ Provider é…ç½®:")
    print("      glm-4.7 (åŸå‚ Anthropic æ ¼å¼):")
    print("         - Endpoint: https://api.z.ai/api/anthropic")
    print("         - ç”¨æ–¼: general, reason-large, big-mid è·¯ç”±")
    print("         - Context: 200K tokens")
    print("         - Max Output: 128K tokens")

    print("\n      minimax-m2.1 (åŸå‚ Anthropic æ ¼å¼):")
    print("         - Endpoint: https://api.minimax.io/anthropic")
    print("         - ç”¨æ–¼: small-fast, fast-reasoning è·¯ç”±")
    print("         - Context: 200K tokens")

    print("\n   ğŸ“‹ æœ¬åœ°ä»£ç† Provider é…ç½® (å¯é¸):")
    print("      glm-local (Port 8082):")
    print("         - éœ€å•Ÿå‹• claude-code-proxy")
    print("         - è¨­ç½® GLM_LOCAL_* ç’°å¢ƒè®Šæ•¸")

    print("\n      minimax-local (Port 8083):")
    print("         - éœ€å•Ÿå‹• claude-code-proxy")
    print("         - è¨­ç½® MINIMAX_LOCAL_* ç’°å¢ƒè®Šæ•¸")

    # æª¢æŸ¥ providers/registry.py ä¸­çš„é…ç½®
    print("\n   ğŸ” æª¢æŸ¥ Provider é…ç½®:")

    try:
        from providers.registry import get_provider

        # æ¸¬è©¦åŸå‚ Provider é…ç½®
        providers_to_check = ["glm-4.7", "minimax-m2.1"]

        for provider_name in providers_to_check:
            try:
                provider = get_provider(provider_name)
                print(f"      âœ… {provider_name}:")
                print(f"         base: {provider.get('base', 'N/A')}")
                print(f"         type: {provider.get('type', 'N/A')}")
                print(f"         model_id: {provider.get('model_id', 'N/A')}")
            except Exception as e:
                print(f"      âš ï¸  {provider_name}: é…ç½®éŒ¯èª¤ - {e}")

        print(f"\n   âœ… Provider é…ç½®æª¢æŸ¥å®Œæˆ")
        return True

    except Exception as e:
        print(f"\n   âš ï¸  Provider é…ç½®æª¢æŸ¥å¤±æ•—: {e}")
        return True  # ä¸å½±éŸ¿ä¸»è¦æ¸¬è©¦

def main():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("\n" + "="*80)
    print("rag.generate æœ¬åœ° Proxy Port æ¸¬è©¦")
    print("="*80)
    print(f"å°ˆæ¡ˆæ ¹ç›®éŒ„: {BASE}")
    print(f"Python: {sys.version}")

    results = {}

    # æ¸¬è©¦ 1: Proxy å¯ç”¨æ€§
    success, available_proxies = test_proxy_availability()
    results["Proxy å¯ç”¨æ€§"] = success

    if not success:
        print("\n" + "="*80)
        print("æ¸¬è©¦ä¸­æ­¢")
        print("="*80)
        print("âš ï¸  ç„¡å¯ç”¨çš„æœ¬åœ° Proxyï¼Œç„¡æ³•ç¹¼çºŒæ¸¬è©¦")
        print("ğŸ“ æç¤º: è«‹å•Ÿå‹•æœ¬åœ° proxy æœå‹™å¾Œé‡è©¦")
        return 1

    # æ¸¬è©¦ 2: Route é…ç½®
    results["Route é…ç½®"] = test_route_configuration()

    # æ¸¬è©¦ 3: answer.generate
    results["answer.generate Route"] = test_answer_generate_with_routes(available_proxies)

    # æ¸¬è©¦ 4: Port ç‰¹å®šåŠŸèƒ½
    results["Port ç‰¹å®šåŠŸèƒ½"] = test_port_specific_features()

    # æ‰“å°æ¸¬è©¦çµæœæ‘˜è¦
    print("\n" + "="*80)
    print("æ¸¬è©¦çµæœæ‘˜è¦")
    print("="*80)

    for test_name, result in results.items():
        status = "âœ… é€šé" if result else "âš ï¸  éœ€æª¢æŸ¥"
        print(f"{status}: {test_name}")

    # çµ±è¨ˆçµæœ
    passed = sum(1 for r in results.values() if r)
    total = len(results)
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} å€‹æ¸¬è©¦éœ€è¦æª¢æŸ¥")
        return 1

if __name__ == "__main__":
    sys.exit(main())
